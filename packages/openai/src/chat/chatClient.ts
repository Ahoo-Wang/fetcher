/*
 * Copyright [2021-present] [ahoo wang <ahoowang@qq.com> (https://github.com/Ahoo-Wang)].
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *      http://www.apache.org/licenses/LICENSE-2.0
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import {
  api,
  type ApiMetadata,
  ApiMetadataCapable,
  autoGeneratedError,
  body,
  ExecuteLifeCycle,
  post,
} from '@ahoo-wang/fetcher-decorator';
import {
  JsonServerSentEventStream,
} from '@ahoo-wang/fetcher-eventstream';
import { FetchExchange } from '@ahoo-wang/fetcher';
import { ChatRequest, ChatResponse } from './types';
import { CompletionStreamResultExtractor } from './completionStreamResultExtractor';

/**
 * OpenAI Chat API Client
 *
 * Provides integration with OpenAI Chat Completions API, supporting both streaming and non-streaming chat completions.
 * Uses decorator pattern for type-safe API calls and automatically handles streaming responses through lifecycle hooks.
 */
@api('chat')
export class ChatClient implements ApiMetadataCapable, ExecuteLifeCycle {
  /**
   * Creates a ChatClient instance
   *
   * @param apiMetadata - Optional API metadata configuration for customizing request behavior
   */
  constructor(public readonly apiMetadata?: ApiMetadata) {}

  /**
   * Lifecycle hook executed before request processing
   *
   * Automatically sets the appropriate result extractor based on the chat request's stream property:
   * - If stream is true, uses CompletionStreamResultExtractor to handle server-sent event streams
   * - If stream is false or undefined, uses the default JSON extractor
   *
   * @param exchange - FetchExchange object containing request and response information
   */
  beforeExecute(exchange: FetchExchange): void {
    const chatRequest = exchange.request.body as ChatRequest;
    if (chatRequest.stream) {
      exchange.resultExtractor = CompletionStreamResultExtractor;
    }
  }

  /**
   * Creates a chat completion
   *
   * Returns different response types based on the stream parameter in the request:
   * - Streaming request (stream: true): Returns JsonServerSentEventStream<ChatResponse>
   * - Non-streaming request (stream: false/undefined): Returns ChatResponse
   *
   * @param chatRequest - Chat request parameters including messages, model configuration, etc.
   * @returns Promise with response type inferred from the stream parameter
   *
   * @example
   * ```typescript
   * // Non-streaming request
   * const response = await client.completions({
   *   model: 'gpt-3.5-turbo',
   *   messages: [{ role: 'user', content: 'Hello!' }],
   *   stream: false
   * });
   * // response: ChatResponse
   *
   * // Streaming request
   * const stream = await client.completions({
   *   model: 'gpt-3.5-turbo',
   *   messages: [{ role: 'user', content: 'Hello!' }],
   *   stream: true
   * });
   * // stream: JsonServerSentEventStream<ChatResponse>
   * ```
   */
  @post('/completions')
  completions<T extends ChatRequest = ChatRequest>(
    @body() chatRequest: T,
  ): Promise<
    T['stream'] extends true
      ? JsonServerSentEventStream<ChatResponse>
      : ChatResponse
  > {
    throw autoGeneratedError(chatRequest);
  }
}
